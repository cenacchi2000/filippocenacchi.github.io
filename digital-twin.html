<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Patient Digital Twin • Filippo Cenacchi</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description"
        content="A 3D clinical digital twin that combines generic anatomy, imaging-driven organs and an interview-based twin model to visualise disease trajectories over time.">

  <style>
    :root{
      --bg:#f7f9fc;--panel:#ffffff;--text:#0b1220;--subtle:#475569;
      --brand:#2563eb;--brand-ink:#1d4ed8;--border:#e5e7eb;
      --shadow:0 10px 32px rgba(15,23,42,0.10);
      --accent-soft:rgba(37,99,235,0.08);
    }
    *{box-sizing:border-box;}
    html,body{
      margin:0;padding:0;min-height:100vh;
      font:16px/1.6 system-ui,-apple-system,Segoe UI,Roboto,Ubuntu;
      color:var(--text);
      background:
        radial-gradient(1200px 700px at 10% -10%,rgba(37,99,235,.18),transparent 55%),
        radial-gradient(900px 600px at 100% 0%,rgba(52,211,153,.15),transparent 55%),
        linear-gradient(180deg,#f7f9fc 0%,#fbfdff 55%,#f7f9fc 100%);
    }
    a{color:var(--brand-ink);text-decoration:none}
    a:hover{text-decoration:underline}
    .container{max-width:980px;margin:0 auto;padding:24px 16px 40px;}
    header{
      display:flex;justify-content:space-between;align-items:center;
      gap:12px;margin-bottom:24px;
    }
    .back-link{
      display:inline-flex;align-items:center;gap:6px;
      padding:6px 10px;border-radius:999px;
      background:#fff;border:1px solid var(--border);
      font-size:14px;box-shadow:0 4px 16px rgba(15,23,42,0.12);
    }
    h1{font-size:clamp(30px,4vw,40px);margin:8px 0 4px;}
    .subtitle{margin:0;color:var(--subtle);font-size:15px;}
    .hero{
      display:grid;
      grid-template-columns:minmax(0,1.2fr) minmax(0,1.4fr);
      gap:28px;align-items:center;margin-bottom:30px;
    }
    .hero-media{
      border-radius:24px;overflow:hidden;border:1px solid var(--border);
      box-shadow:var(--shadow);background:#020617;
      max-height:460px;min-height:260px;
    }
    .hero-media img{
      width:100%;height:100%;object-fit:cover;display:block;
    }
    .pill{
      display:inline-flex;align-items:center;gap:8px;
      padding:6px 10px;border-radius:999px;
      background:rgba(15,23,42,0.03);
      border:1px solid rgba(148,163,184,0.6);
      font-size:13px;color:var(--subtle);
    }
    .pill span.dot{width:8px;height:8px;border-radius:999px;background:#22c55e;}
    section{
      margin-bottom:26px;background:var(--panel);border-radius:18px;
      border:1px solid var(--border);box-shadow:var(--shadow);
      padding:18px 20px 18px;
    }
    section h2{margin-top:0;font-size:20px;}
    .tag-row{margin-top:8px;display:flex;flex-wrap:wrap;gap:6px;}
    .tag{
      font-size:12px;padding:4px 9px;border-radius:999px;
      background:var(--accent-soft);color:var(--brand-ink);
      border:1px solid rgba(37,99,235,0.25);
    }
    .two-col{
      display:grid;grid-template-columns:minmax(0,1.2fr) minmax(0,1fr);
      gap:18px;
    }
    @media(max-width:800px){
      .hero{grid-template-columns:1fr;}
      .hero-media{order:-1;}
      .two-col{grid-template-columns:1fr;}
    }
    .callout{
      margin:0;padding:12px 14px;border-radius:12px;
      background:rgba(34,197,94,0.07);
      border-left:4px solid #22c55e;
      font-size:14px;color:var(--subtle);
    }
    .small{font-size:14px;color:var(--subtle);}
    .live-embed{
      margin-top:12px;
      border-radius:18px;
      border:1px solid #0f172a;
      overflow:hidden;
      box-shadow:var(--shadow);
      background:#020617;
    }
    .live-embed iframe{
      width:100%;
      min-height:680px;
      border:0;
      display:block;
    }
    @media(max-width:600px){
      .live-embed iframe{min-height:560px;}
    }
  </style>
</head>
<body>
  <div class="container">
    <header>
      <a class="back-link" href="index.html#research">← Back to research overview</a>
      <span class="small">Filippo Cenacchi · Patient Digital Twin</span>
    </header>

    <div class="hero">
      <div>
        <p class="pill">
          <span class="dot"></span>
          3D clinical avatar · Imaging-guided digital twin
        </p>
        <h1>Patient Digital Twin (Imaging-Guided)</h1>
        <p class="subtitle">
          A research prototype that couples a generic 3D anatomical avatar with CT-like
          organ volumes and a rule-based LLM interview to visualise how lifestyle and
          pathology reshape organs over time. Not a medical device.
        </p>
        <div class="tag-row" style="margin-top:10px;">
          <span class="tag">Human Reference Atlas</span>
          <span class="tag">Longitudinal imaging</span>
          <span class="tag">Organ-level risk fields</span>
          <span class="tag">Digital twin analytics</span>
        </div>
      </div>
      <figure class="hero-media">
        <img src="twin.png"
             alt="3D anatomical avatar with isolated vascular tree and organ panel">
      </figure>
    </div>

    <section>
      <h2>Overview</h2>
      <p>
        The Patient Digital Twin prototype turns raw clinical ingredients into a
        manipulable 3D avatar. A whole-body anatomical mesh (from the Human Reference
        Atlas) is combined with organ-specific 3D meshes extracted from volumetric
        scans. A lightweight twin model tracks demographics, lifestyle and organ
        risk, and drives both the avatar’s visuals and a composite health index.
      </p>
      <p>
        The goal is not diagnosis, but <strong>explainable visualisation</strong>:
        given the same underlying imaging data, how can we make organ trajectories,
        risk concentration and the impact of simple “what-if” scenarios tangible
        for clinicians, patients and AI developers?
      </p>
    </section>

    <section>
      <h2>Key Contributions</h2>
      <div class="two-col">
        <div>
          <p>
            <strong>1. 3D Clinical Avatar with HRA organ focusing.</strong>
            The app renders a generic male/female anatomical avatar, then
            overlays high-resolution organ meshes dynamically fetched from the
            Human Reference Atlas. Clinicians can “spotlight” an organ in a
            separate pane while keeping the whole-body context in view.
          </p>
          <p>
            <strong>2. Imaging-driven organ risk surfaces.</strong>
            For each CT-like volume in the longitudinal dataset, the pipeline
            extracts an organ mask, builds an iso-surface mesh via marching cubes
            and colours every vertex by an intensity-derived risk score. Higher
            risk regions “glow” on the mesh, grounding the visualisation in the
            actual voxel data, not hand-drawn shapes.
          </p>
        </div>
        <div>
          <p>
            <strong>3. Simulated future progression.</strong>
            Starting from the last available scan, the twin extrapolates organ
            evolution into the future by expanding or shrinking high-risk regions
            and applying mesh deformations. This yields a phenomenological—but
            visually coherent—trajectory of tumour burden worsening or treatment
            response across 5–30 years.
          </p>
          <p>
            <strong>4. Interview-driven twin state.</strong>
            A rule-based “LLM agent” asks a short sequence of questions
            (age, activity, diet, smoking) and updates organ-level risk indices
            and a global health score in real time. This demonstrates how
            language-level inputs can be wired into the same twin that is driven
            by imaging features.
          </p>
        </div>
      </div>
    </section>

    <section>
      <h2>Interactive Dashboard (Live Demo)</h2>
      <p class="small">
        The panel below embeds a running instance of the
        <strong>Patient Digital Twin</strong> Streamlit dashboard hosted on
        Hugging Face Spaces. You can scroll, switch patients, scrub the
        timeline and watch the 3D organ mesh and risk gauges respond.
      </p>

      <div class="live-embed">
        <iframe
          src="https://filo-cenacchi-patient-digital-twin.hf.space"
          title="Patient Digital Twin – live dashboard"
          loading="lazy"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
          allowfullscreen
        ></iframe>
      </div>

      <p class="small" style="margin-top:10px;">
        If the embedded window does not load correctly, open the demo directly on
        Hugging Face:
        <a href="https://huggingface.co/spaces/filo-cenacchi/Patient_digital-twin"
           target="_blank" rel="noreferrer">
          Patient_digital-twin · Hugging Face Spaces ↗
        </a>
      </p>
    </section>

    <section>
      <h2>Model &amp; Data Flow</h2>
      <div class="two-col">
        <div>
          <p>
            Each imaging timepoint is defined in a small CSV index
            (<code>patients_index.csv</code>) that links a <code>patient_id</code>,
            target <code>organ</code>, acquisition <code>year</code> and file paths
            for the volume and (optionally) a segmentation mask. Volumes can be
            synthetic <code>.npy</code> arrays or NIfTI files.
          </p>
          <p>
            The app loads the volume, normalises intensities and uses
            <code>skimage.measure.marching_cubes</code> to extract an iso-surface
            mesh. Vertex-wise “pathology intensity” is computed by comparing each
            voxel against an organ-specific HU band (e.g. low-density pockets in
            lungs, hyperdense lesions in liver), then normalised to a 0–1 risk field.
          </p>
        </div>
        <div>
          <p>
            Future years re-use the last observed mesh and deform it via a simple
            phenomenological model: high-risk vertices bulge outwards and expand
            under a “worsening” scenario, or contract and fade under an
            “improvement” scenario. This gives a controllable, anatomy-respecting
            visual trajectory without claiming full biophysical realism.
          </p>
          <p>
            In parallel, a structured twin object aggregates demographics,
            lifestyle sliders, organ risk scores and BMI into a composite health
            score (0–100). This state is persisted locally and displayed in the
            sidebar to illustrate how <strong>avatar, imaging and numbers all
            share the same underlying twin representation.</strong>
          </p>
        </div>
      </div>
    </section>

    <section>
      <h2>Ethical &amp; Clinical Positioning</h2>
      <p class="callout">
        This prototype is a <strong>research visualisation tool only</strong>.
        It has no diagnostic guarantees and must not be used for clinical
        decision-making. Parameters, risk mappings and progression dynamics are
        deliberately simplified to make the pipeline transparent and easy to
        inspect.
      </p>
      <p>
        The broader research agenda asks how such imaging-grounded twins could
        support explainable AI pipelines: clinicians can see <em>where</em> a
        model concentrates risk inside an organ, simulate counterfactual
        lifestyle changes, and share de-identified variants with other sites.
        Future work will tighten the link to real datasets, add formal
        de-identification guarantees and integrate the avatar with humanoid
        agents like Ameca for in-situ explanation.
      </p>
    </section>
  </div>
</body>
</html>
